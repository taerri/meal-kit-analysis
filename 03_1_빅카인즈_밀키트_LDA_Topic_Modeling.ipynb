{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03-1_빅카인즈_밀키트_LDA_Topic Modeling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taerri/meal-kit-analysis/blob/main/03_1_%EB%B9%85%EC%B9%B4%EC%9D%B8%EC%A6%88_%EB%B0%80%ED%82%A4%ED%8A%B8_LDA_Topic_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meTwDF8W0wJB"
      },
      "source": [
        "# **토픽모델링**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv1VE9epC8B9"
      },
      "source": [
        "### **데이터 읽기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7zj87760wJD"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "3k2yjw9q0wJE",
        "outputId": "4d2bdf5c-9f3a-42b7-d66f-138df2cf3cb8"
      },
      "source": [
        "#데이터 읽기\n",
        "Corpus_all = pd.read_csv(\"밀키트 뉴스데이터 전처리_최종.csv\", encoding=\"utf8\")\n",
        "print(\"데이터 개수 :\",len(Corpus_all))\n",
        "Corpus_all.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 개수 : 5506\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>키워드</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>재배,채소,제공,웰빙,먹거리,하이원리조트,요리사,셰프들,재배,채소,식재료,활용,손님...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>백화점,롯데쇼핑,매출,역성장,실적,롯데쇼핑,백화점,회복세,롯데마트,롯데하이마트,e커...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>밀키트,창업,가정,안산시,밀키트,기탁,브랜드,100호,밀키트,창업,브랜드,최단,기간...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>수산물,할인,정부,소비,촉진,정부,할인,쿠폰,발행,지원,추가,코로나19,최소화,전통...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>소상공인,구독,경제,바우처,제공,소상공인,구독경제,중소벤처기업부,비상,경제,중앙,대...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                                키워드\n",
              "0           0  재배,채소,제공,웰빙,먹거리,하이원리조트,요리사,셰프들,재배,채소,식재료,활용,손님...\n",
              "1           1  백화점,롯데쇼핑,매출,역성장,실적,롯데쇼핑,백화점,회복세,롯데마트,롯데하이마트,e커...\n",
              "2           2  밀키트,창업,가정,안산시,밀키트,기탁,브랜드,100호,밀키트,창업,브랜드,최단,기간...\n",
              "3           3  수산물,할인,정부,소비,촉진,정부,할인,쿠폰,발행,지원,추가,코로나19,최소화,전통...\n",
              "4           4  소상공인,구독,경제,바우처,제공,소상공인,구독경제,중소벤처기업부,비상,경제,중앙,대..."
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzlnUgae0wJH"
      },
      "source": [
        "### **주요 단어 빈도 확인**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT4xVAPs0wJI"
      },
      "source": [
        "Corpus_org = Corpus_all[\"키워드\"]\n",
        "Corpus = [wl.split(\",\")  for wl in Corpus_org]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHtwftskbTGe"
      },
      "source": [
        "def isHangulOrAlphabet(word):\n",
        "    return word[0].isalpha() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZ8qkZUQbTGf",
        "outputId": "e5cba3e1-7375-4335-da86-c81a134d8021"
      },
      "source": [
        "isHangulOrAlphabet(\"12\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8qlZQar3fs0",
        "outputId": "a28ec4a9-4d08-4b58-a035-2faac55e7e06"
      },
      "source": [
        "for wl in Corpus[:3]:\n",
        "  print(wl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['재배', '채소', '제공', '웰빙', '먹거리', '하이원리조트', '요리사', '셰프들', '재배', '채소', '식재료', '활용', '손님', '웰빙', '먹거리', '제공', '호평', '셰프들', '하이원리조트', '호텔', '셰프', '주인공', '호텔', '셰프', '키친', '오가닉팜', '운영', '고객', '건강', '먹거리', '새싹', '허브', '제공', '고객서비스', '에코', '캠페인', '키친가든', '식재료', '활용', '채소', '허브', '열매', '정원', '키친', '오가닉팜', '하이원리조트', '운암정', '조성', '호텔', '셰프', '구슬땀', '20여종', '채소', '허브', '재배', '재배', '채소', '허브', '호텔', '위치', '식음업장', '식재료', '활용', '하이원리조트', 'PB', '상품', 'GOURMET', '고메', '밀키트', '제품', '이용', '채소', '허브', '농법', '재배', '강원랜드', '사내', '벤처', '자원업사이클TF', '도움', '리조트', '배출', '음식물', '쓰레기', '동애등에', '곤충', '먹이', '활용', '자연', '분해', '퇴비', '지원', '활용', '하이원리조트', '조리', '이태규', '부장', '하이원리조트', '호텔', '손님', '정성', '재배', '식재료', '활용', '음식', '대접', '수요', '음식', '노력']\n",
            "['백화점', '롯데쇼핑', '매출', '역성장', '실적', '롯데쇼핑', '백화점', '회복세', '롯데마트', '롯데하이마트', 'e커머스', '롯데온', '주력', '계열사', '부진', '매출', '역성장', '구조', '조정', '성과', '영업이익', '444%', '증가', '시장', '롯데쇼핑', '영업', '이익', '75억', '444.7%', '동기', '대비', '444.7%', '공시', '매출액', '3.5%', '감소', '영업이익', '송도롯데몰', '공사', '지연', '323억', '추징', '세금', '영향', '비용', '제외', '영업', '399억', '시장', '롯데쇼핑', '7조', '매출', '영업이익', '600억', '기록', '예상', '사업부별', '보복', '소비', '효과', '백화점', '매출', '영업이익', '성장', '백화점', '매출', '7210억', '8.2%', '영업이익', '620억', '40.9%', '급증', '회복', '소비', '지속', '해외', '사업', '기조', '효과', '영향', '고성장', '설명', '신장률', '기존점', '신장', '10.3%', '만큼', '회복', '성공', '모습', '할인', '롯데마트', '지점', '축소', '매출', '감소', '부진', '점포', '축소', '매출', '4.8%', '구조', '조정', '효과', '영업적자', '260억', '390억', '개선', '주류', '신선식품', '밀키트', '자릿수', '성장', '기존점', '신장', '1.7%', '성장', '롯데하이마트', '5~6월', '여름', '기온', '에어컨', '판매', '부진', '매출', '동기', '대비', '매출액', '영업이익', '11.4%', '52.3%', '성장세', '제동', '온라인', '성장', '동기', '대비', '26%', '증가', '무더위', '시작', '에어컨', '판매', '실적', '반등', '예상', '슈퍼', '16.8%', '매출', '감소', '부진', '홈쇼핑', '마케팅', '강화', '영업이익', '18.1%', '매출액', '4.9%', '컬처웍스', '기저', '효과', '영향', '매출액', '36.6%', '430억', '기록', '전사적', 'e커머스', '부진', '2분기', '사업부', '매출', '10.4%', '290억', '기록', '셀러', '수수료', '인하', '영향', '영향', '회계', '기준', '변경', '반영', '설명', '영업', '적자', '적자', '확대', '광고', '판촉비', '판관비', '안정', '확대', '비용', '증가', '롯데쇼핑', '관계자', '오픈', '롯데온', '회계', '기준', '영향', '2분기', '반영', '거래액', '트래픽', '지속적', '증가']\n",
            "['밀키트', '창업', '가정', '안산시', '밀키트', '기탁', '브랜드', '100호', '밀키트', '창업', '브랜드', '최단', '기간', '돌파', '저소득가정', '안산시', '관내', '소득', '가정', '이웃', '사랑', '후원', '2천만', '밀키트', '기탁', '안산시', '안산시청', '윤화섭', '안산', '시장', '대표이사', '박상미', '영상', '에프앤비', '대표', '이사', '참석', '전달식', '기탁', '100~200개', '2', '밀키트', '제품', '생활', '1인', '가정', '제공', '예정', '냉장', '냉동', '식품', '감안', '기부식품제공사업장', '푸드뱅크', '기탁처리', '제공', '예정', '관계자', '사회', '거리', '강화', '사회', '복지', '시설', '운영', '축소', '소식', '사회', '공헌', '활동', '마련', '고객', '사랑', '사회', '환원', '활동', '기업', '사회', '책임', '대표', '밀키트', '전문점', '여파', '창업', '시장', '전반적', '침체기', '와중', '100호', '최단', '기간', '가맹', '계약', '체결', '밀키트', '창업', '프랜차이즈', '업계', '활약']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMeIcREb0wJJ"
      },
      "source": [
        "def Word_count(corpus):\n",
        "    word_cnt = dict()\n",
        "    for text in corpus:\n",
        "        for word in text:\n",
        "            if word_cnt.get(word):\n",
        "                word_cnt[word]+=1\n",
        "            else:\n",
        "                word_cnt[word]=1\n",
        "    cnt_df = pd.DataFrame.from_dict(word_cnt, orient='index')\n",
        "    cnt_df.columns = [\"개수\"]\n",
        "    cnt_df = cnt_df.sort_values([\"개수\"],ascending=False)\n",
        "    return word_cnt, cnt_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F9oF-VY0wJK"
      },
      "source": [
        "Words_cnt, Cnt_df = Word_count(Corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYlhGfazKn9Q",
        "outputId": "103c6d6f-52ae-4bca-daa4-f6101e639822"
      },
      "source": [
        "len(Cnt_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63678"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZA9_LMs0wJL"
      },
      "source": [
        "# 저장\n",
        "Cnt_df.to_csv(\"주요 단어빈도.csv\", encoding=\"utf-8-sig\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4b6_RB60wJP"
      },
      "source": [
        "# **3-1 LDA  토픽모델링**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blK8EpCAC8CY",
        "outputId": "6e2a758d-104d-42a0-892e-3c54fddffe61"
      },
      "source": [
        "pip install gensim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.1.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86H7SXcXC8Ca",
        "outputId": "9c465939-6612-4f5b-e76d-dc10f79b06d9"
      },
      "source": [
        "pip install pyLDAvis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.22.2.post1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.21.2)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.16)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (57.4.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.1)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.7.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (5.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg4DGne90wJQ"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import pickle\n",
        "from gensim import corpora\n",
        "import gensim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCpL6iqA0wJQ"
      },
      "source": [
        "class LDA_model:\n",
        "    def __init__(self,corpus):\n",
        "        self.corpus = corpus\n",
        "        return;\n",
        "    def mk_detokenized_doc(self):\n",
        "        self.detokenized_doc = []\n",
        "        for i in range(len(self.corpus)):\n",
        "            try:\n",
        "                t = ' '.join(self.corpus.iloc[i])\n",
        "                self.detokenized_doc.append(t)\n",
        "            except:\n",
        "                print(i)\n",
        "        return;\n",
        "    def tf_idf_vector(self,max_features):\n",
        "        self.vectorizer = TfidfVectorizer(max_features= max_features) # 상위 1000개의 단어 보존\n",
        "        self.X = self.vectorizer.fit_transform(self.detokenized_doc)\n",
        "        return;\n",
        "    def mk_word2id(self):\n",
        "        self.word2id = defaultdict(lambda : 0)\n",
        "        for idx, feature in enumerate(self.vectorizer.get_feature_names()):\n",
        "            self.word2id[feature] = idx\n",
        "        return;\n",
        "    def print_word2id(self,n=1):\n",
        "        for i, sent in enumerate(self.detokenized_doc):\n",
        "            print('====== document[%d] ======' % i)\n",
        "            print( [ (token, self.X[i, self.word2id[token]]) for token in sent.split() ] )\n",
        "            if i==n:\n",
        "                break\n",
        "        return;\n",
        "    def mk_lda_model(self,n_topic=10,max_iter=1):\n",
        "        self.lda_model=LatentDirichletAllocation(n_components=n_topic,learning_method='online',random_state=777,max_iter=max_iter)\n",
        "        self.lda_top=self.lda_model.fit_transform(self.X)\n",
        "        return;\n",
        "    def print_lda(self):\n",
        "        print(\"-------------------------------------\")\n",
        "        print(self.lda_model.components_)\n",
        "        print(self.lda_model.components_.shape) \n",
        "        return;\n",
        "    def print_topic_lda(self,n=5):\n",
        "        print(\"-------------------------------------\")\n",
        "        terms = self.vectorizer.get_feature_names() # 단어 집합. 1,000개의 단어가 저장됨.\n",
        "        for idx, topic in enumerate(self.lda_model.components_):\n",
        "            print(\"Topic %d:\" % (idx+1), [(terms[i], topic[i].round(2)) for i in topic.argsort()[:-n - 1:-1]])\n",
        "        return;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dZmh7VX0wJQ"
      },
      "source": [
        "model_all = LDA_model(Corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOsm3Afl0wJR"
      },
      "source": [
        "# **3-2 LDA 토픽모델링 시각화**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lwl83ZDB0wJR"
      },
      "source": [
        "- 토픽별 단어 분포"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOjVHLSR0wJS",
        "outputId": "17f2dfb6-35af-4914-c374-148b45b16226"
      },
      "source": [
        "dictionary = corpora.Dictionary(model_all.corpus)\n",
        "corpus = [dictionary.doc2bow(text) for text in model_all.corpus]\n",
        "NUM_TOPICS = 9\n",
        "num_words = 30\n",
        "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
        "topics = ldamodel.print_topics(num_words=num_words)\n",
        "for topic in topics:\n",
        "    print(topic)\n",
        "dictionary.save('dictionary_전처리.gensim')\n",
        "pickle.dump(corpus, open('corpus_전처리.pkl', 'wb'))\n",
        "ldamodel.save('gensim_model_전처리.gensim')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.043*\"밀키트\" + 0.020*\"시장\" + 0.019*\"제품\" + 0.015*\"매출\" + 0.014*\"간편식\" + 0.013*\"요리\" + 0.010*\"메뉴\" + 0.010*\"출시\" + 0.010*\"판매\" + 0.010*\"증가\" + 0.008*\"브랜드\" + 0.008*\"식품\" + 0.008*\"조리\" + 0.007*\"식재료\" + 0.006*\"인기\" + 0.006*\"대비\" + 0.006*\"이마트\" + 0.006*\"상품\" + 0.006*\"가정\" + 0.006*\"성장\" + 0.006*\"재료\" + 0.005*\"소비자\" + 0.005*\"손질\" + 0.005*\"피코크\" + 0.005*\"CJ제일제당\" + 0.005*\"관계자\" + 0.005*\"확대\" + 0.004*\"레시피\" + 0.004*\"수요\" + 0.004*\"셰프\"')\n",
            "(1, '0.012*\"식품\" + 0.009*\"사업\" + 0.008*\"대표\" + 0.007*\"기업\" + 0.007*\"창업\" + 0.006*\"산업\" + 0.005*\"지역\" + 0.005*\"지원\" + 0.004*\"생산\" + 0.004*\"선정\" + 0.004*\"분야\" + 0.004*\"시장\" + 0.004*\"공간\" + 0.004*\"제품\" + 0.004*\"스타트업\" + 0.004*\"코로나19\" + 0.003*\"미국\" + 0.003*\"밀키트\" + 0.003*\"활용\" + 0.003*\"식물\" + 0.003*\"교육\" + 0.003*\"푸드\" + 0.003*\"회사\" + 0.003*\"가치\" + 0.003*\"한국\" + 0.003*\"운영\" + 0.003*\"제조\" + 0.003*\"현대그린푸드\" + 0.003*\"중국\" + 0.003*\"진행\"')\n",
            "(2, '0.013*\"행사\" + 0.012*\"판매\" + 0.012*\"할인\" + 0.008*\"온라인\" + 0.008*\"코로나19\" + 0.008*\"지역\" + 0.007*\"진행\" + 0.007*\"상품\" + 0.007*\"이마트\" + 0.006*\"매장\" + 0.006*\"홈플러스\" + 0.006*\"밀키트\" + 0.005*\"점포\" + 0.004*\"최대\" + 0.004*\"방송\" + 0.004*\"기간\" + 0.004*\"구매\" + 0.004*\"연휴\" + 0.004*\"운영\" + 0.004*\"준비\" + 0.003*\"가격\" + 0.003*\"백종원\" + 0.003*\"지원\" + 0.003*\"참여\" + 0.003*\"전국\" + 0.003*\"마트\" + 0.003*\"추석\" + 0.003*\"라이브\" + 0.003*\"대표\" + 0.003*\"사회\"')\n",
            "(3, '0.016*\"사업\" + 0.014*\"기업\" + 0.013*\"지원\" + 0.013*\"투자\" + 0.009*\"시장\" + 0.009*\"밀키트\" + 0.008*\"프레시지\" + 0.007*\"대표\" + 0.007*\"유통\" + 0.006*\"소상공인\" + 0.006*\"성장\" + 0.006*\"계획\" + 0.006*\"업체\" + 0.005*\"확대\" + 0.005*\"온라인\" + 0.005*\"제품\" + 0.005*\"스타트업\" + 0.005*\"플랫폼\" + 0.004*\"코로나19\" + 0.004*\"생산\" + 0.004*\"경제\" + 0.004*\"식품\" + 0.004*\"규모\" + 0.004*\"추진\" + 0.004*\"매출\" + 0.004*\"선정\" + 0.004*\"지역\" + 0.004*\"구축\" + 0.004*\"운영\" + 0.004*\"강화\"')\n",
            "(4, '0.013*\"밀키트\" + 0.011*\"요리\" + 0.011*\"메뉴\" + 0.010*\"출시\" + 0.010*\"제품\" + 0.008*\"음식\" + 0.007*\"스테이크\" + 0.007*\"인기\" + 0.007*\"판매\" + 0.006*\"세트\" + 0.006*\"구성\" + 0.006*\"상품\" + 0.006*\"셰프\" + 0.005*\"프리미엄\" + 0.005*\"브랜드\" + 0.005*\"홈파티\" + 0.004*\"캠핑\" + 0.004*\"레스토랑\" + 0.004*\"준비\" + 0.004*\"소스\" + 0.004*\"크리스마스\" + 0.004*\"명절\" + 0.004*\"연말\" + 0.004*\"방송\" + 0.003*\"사용\" + 0.003*\"레시피\" + 0.003*\"와인\" + 0.003*\"재료\" + 0.003*\"프레시지\" + 0.003*\"진행\"')\n",
            "(5, '0.030*\"서비스\" + 0.030*\"배송\" + 0.018*\"배달\" + 0.017*\"주문\" + 0.011*\"한국야쿠르트\" + 0.010*\"고객\" + 0.008*\"온라인\" + 0.008*\"제품\" + 0.007*\"상품\" + 0.006*\"확대\" + 0.006*\"이용\" + 0.005*\"운영\" + 0.005*\"시장\" + 0.005*\"증가\" + 0.005*\"시작\" + 0.005*\"식품\" + 0.005*\"신선\" + 0.005*\"모바일\" + 0.005*\"가능\" + 0.004*\"쇼핑\" + 0.004*\"제공\" + 0.004*\"물류\" + 0.004*\"매출\" + 0.004*\"정기\" + 0.004*\"소비자\" + 0.004*\"야쿠르트\" + 0.004*\"지역\" + 0.004*\"코로나19\" + 0.004*\"플랫폼\" + 0.004*\"잇츠온\"')\n",
            "(6, '0.031*\"상품\" + 0.018*\"고객\" + 0.012*\"배송\" + 0.011*\"심플리쿡\" + 0.011*\"서비스\" + 0.011*\"온라인\" + 0.010*\"판매\" + 0.010*\"GS리테일\" + 0.010*\"구매\" + 0.009*\"GS\" + 0.009*\"할인\" + 0.008*\"제공\" + 0.007*\"진행\" + 0.007*\"밀키트\" + 0.007*\"브랜드\" + 0.007*\"이마트\" + 0.006*\"확대\" + 0.006*\"식품\" + 0.006*\"매장\" + 0.006*\"운영\" + 0.006*\"GS25\" + 0.005*\"구독\" + 0.005*\"오프라인\" + 0.005*\"행사\" + 0.005*\"이벤트\" + 0.005*\"최대\" + 0.004*\"혜택\" + 0.004*\"롯데슈퍼\" + 0.004*\"가능\" + 0.004*\"지역\"')\n",
            "(7, '0.007*\"가구\" + 0.007*\"코로나19\" + 0.007*\"소비\" + 0.006*\"음식\" + 0.006*\"트렌드\" + 0.005*\"건강\" + 0.004*\"증가\" + 0.004*\"변화\" + 0.004*\"사람\" + 0.004*\"가족\" + 0.004*\"식사\" + 0.004*\"요리\" + 0.003*\"공간\" + 0.003*\"제품\" + 0.003*\"생각\" + 0.003*\"생활\" + 0.003*\"조사\" + 0.003*\"사람들\" + 0.003*\"세대\" + 0.003*\"온라인\" + 0.003*\"시대\" + 0.003*\"확산\" + 0.003*\"문화\" + 0.003*\"사용\" + 0.002*\"사회\" + 0.002*\"이용\" + 0.002*\"결과\" + 0.002*\"전망\" + 0.002*\"정도\" + 0.002*\"밀키트\"')\n",
            "(8, '0.025*\"선물\" + 0.016*\"세트\" + 0.012*\"판매\" + 0.012*\"밀키트\" + 0.008*\"산천어\" + 0.008*\"명절\" + 0.007*\"추석\" + 0.007*\"KT\" + 0.006*\"진행\" + 0.005*\"광화문\" + 0.005*\"사회\" + 0.004*\"제공\" + 0.004*\"구매\" + 0.004*\"지역\" + 0.004*\"사랑\" + 0.004*\"전달\" + 0.004*\"코로나19\" + 0.004*\"선물세트\" + 0.004*\"지원\" + 0.004*\"서비스\" + 0.004*\"구성\" + 0.004*\"준비\" + 0.003*\"축제\" + 0.003*\"캠페인\" + 0.003*\"조리\" + 0.003*\"식당\" + 0.003*\"큐커\" + 0.003*\"보양식\" + 0.003*\"대상\" + 0.003*\"한우\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B889GseaJ3WK",
        "outputId": "eef25778-251b-48da-9fe6-95f6f4bf9dbf"
      },
      "source": [
        "pip install pyLDAvis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.1)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.21.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.22.2.post1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.16)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (57.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (5.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRJpW46dbTG2",
        "outputId": "43c9aabd-08b7-4d40-d79a-2441f99ffd5c"
      },
      "source": [
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim_models.prepare(ldamodel, corpus, dictionary)\n",
        "pyLDAvis.save_html(vis,\"lda_전처리.html\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Iterable\n",
            "/usr/local/lib/python3.7/dist-packages/pyLDAvis/_prepare.py:247: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  by='saliency', ascending=False).head(R).drop('saliency', 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW-8Ng220wJT",
        "outputId": "2cdf099d-a6ec-40d2-f865-451a8d2609f6"
      },
      "source": [
        "len(dictionary) # 각 단어의 정수형 표시"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63678"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnjLTNhz0wJT",
        "outputId": "7d4f4e5a-ab27-4be2-cf98-c27e2c144ac5"
      },
      "source": [
        "NUM_TOPICS = 9\n",
        "num_words = 30\n",
        "#ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
        "topics = ldamodel.print_topics(num_words=num_words)\n",
        "for topic in topics:\n",
        "    print(topic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.043*\"밀키트\" + 0.020*\"시장\" + 0.019*\"제품\" + 0.015*\"매출\" + 0.014*\"간편식\" + 0.013*\"요리\" + 0.010*\"메뉴\" + 0.010*\"출시\" + 0.010*\"판매\" + 0.010*\"증가\" + 0.008*\"브랜드\" + 0.008*\"식품\" + 0.008*\"조리\" + 0.007*\"식재료\" + 0.006*\"인기\" + 0.006*\"대비\" + 0.006*\"이마트\" + 0.006*\"상품\" + 0.006*\"가정\" + 0.006*\"성장\" + 0.006*\"재료\" + 0.005*\"소비자\" + 0.005*\"손질\" + 0.005*\"피코크\" + 0.005*\"CJ제일제당\" + 0.005*\"관계자\" + 0.005*\"확대\" + 0.004*\"레시피\" + 0.004*\"수요\" + 0.004*\"셰프\"')\n",
            "(1, '0.012*\"식품\" + 0.009*\"사업\" + 0.008*\"대표\" + 0.007*\"기업\" + 0.007*\"창업\" + 0.006*\"산업\" + 0.005*\"지역\" + 0.005*\"지원\" + 0.004*\"생산\" + 0.004*\"선정\" + 0.004*\"분야\" + 0.004*\"시장\" + 0.004*\"공간\" + 0.004*\"제품\" + 0.004*\"스타트업\" + 0.004*\"코로나19\" + 0.003*\"미국\" + 0.003*\"밀키트\" + 0.003*\"활용\" + 0.003*\"식물\" + 0.003*\"교육\" + 0.003*\"푸드\" + 0.003*\"회사\" + 0.003*\"가치\" + 0.003*\"한국\" + 0.003*\"운영\" + 0.003*\"제조\" + 0.003*\"현대그린푸드\" + 0.003*\"중국\" + 0.003*\"진행\"')\n",
            "(2, '0.013*\"행사\" + 0.012*\"판매\" + 0.012*\"할인\" + 0.008*\"온라인\" + 0.008*\"코로나19\" + 0.008*\"지역\" + 0.007*\"진행\" + 0.007*\"상품\" + 0.007*\"이마트\" + 0.006*\"매장\" + 0.006*\"홈플러스\" + 0.006*\"밀키트\" + 0.005*\"점포\" + 0.004*\"최대\" + 0.004*\"방송\" + 0.004*\"기간\" + 0.004*\"구매\" + 0.004*\"연휴\" + 0.004*\"운영\" + 0.004*\"준비\" + 0.003*\"가격\" + 0.003*\"백종원\" + 0.003*\"지원\" + 0.003*\"참여\" + 0.003*\"전국\" + 0.003*\"마트\" + 0.003*\"추석\" + 0.003*\"라이브\" + 0.003*\"대표\" + 0.003*\"사회\"')\n",
            "(3, '0.016*\"사업\" + 0.014*\"기업\" + 0.013*\"지원\" + 0.013*\"투자\" + 0.009*\"시장\" + 0.009*\"밀키트\" + 0.008*\"프레시지\" + 0.007*\"대표\" + 0.007*\"유통\" + 0.006*\"소상공인\" + 0.006*\"성장\" + 0.006*\"계획\" + 0.006*\"업체\" + 0.005*\"확대\" + 0.005*\"온라인\" + 0.005*\"제품\" + 0.005*\"스타트업\" + 0.005*\"플랫폼\" + 0.004*\"코로나19\" + 0.004*\"생산\" + 0.004*\"경제\" + 0.004*\"식품\" + 0.004*\"규모\" + 0.004*\"추진\" + 0.004*\"매출\" + 0.004*\"선정\" + 0.004*\"지역\" + 0.004*\"구축\" + 0.004*\"운영\" + 0.004*\"강화\"')\n",
            "(4, '0.013*\"밀키트\" + 0.011*\"요리\" + 0.011*\"메뉴\" + 0.010*\"출시\" + 0.010*\"제품\" + 0.008*\"음식\" + 0.007*\"스테이크\" + 0.007*\"인기\" + 0.007*\"판매\" + 0.006*\"세트\" + 0.006*\"구성\" + 0.006*\"상품\" + 0.006*\"셰프\" + 0.005*\"프리미엄\" + 0.005*\"브랜드\" + 0.005*\"홈파티\" + 0.004*\"캠핑\" + 0.004*\"레스토랑\" + 0.004*\"준비\" + 0.004*\"소스\" + 0.004*\"크리스마스\" + 0.004*\"명절\" + 0.004*\"연말\" + 0.004*\"방송\" + 0.003*\"사용\" + 0.003*\"레시피\" + 0.003*\"와인\" + 0.003*\"재료\" + 0.003*\"프레시지\" + 0.003*\"진행\"')\n",
            "(5, '0.030*\"서비스\" + 0.030*\"배송\" + 0.018*\"배달\" + 0.017*\"주문\" + 0.011*\"한국야쿠르트\" + 0.010*\"고객\" + 0.008*\"온라인\" + 0.008*\"제품\" + 0.007*\"상품\" + 0.006*\"확대\" + 0.006*\"이용\" + 0.005*\"운영\" + 0.005*\"시장\" + 0.005*\"증가\" + 0.005*\"시작\" + 0.005*\"식품\" + 0.005*\"신선\" + 0.005*\"모바일\" + 0.005*\"가능\" + 0.004*\"쇼핑\" + 0.004*\"제공\" + 0.004*\"물류\" + 0.004*\"매출\" + 0.004*\"정기\" + 0.004*\"소비자\" + 0.004*\"야쿠르트\" + 0.004*\"지역\" + 0.004*\"코로나19\" + 0.004*\"플랫폼\" + 0.004*\"잇츠온\"')\n",
            "(6, '0.031*\"상품\" + 0.018*\"고객\" + 0.012*\"배송\" + 0.011*\"심플리쿡\" + 0.011*\"서비스\" + 0.011*\"온라인\" + 0.010*\"판매\" + 0.010*\"GS리테일\" + 0.010*\"구매\" + 0.009*\"GS\" + 0.009*\"할인\" + 0.008*\"제공\" + 0.007*\"진행\" + 0.007*\"밀키트\" + 0.007*\"브랜드\" + 0.007*\"이마트\" + 0.006*\"확대\" + 0.006*\"식품\" + 0.006*\"매장\" + 0.006*\"운영\" + 0.006*\"GS25\" + 0.005*\"구독\" + 0.005*\"오프라인\" + 0.005*\"행사\" + 0.005*\"이벤트\" + 0.005*\"최대\" + 0.004*\"혜택\" + 0.004*\"롯데슈퍼\" + 0.004*\"가능\" + 0.004*\"지역\"')\n",
            "(7, '0.007*\"가구\" + 0.007*\"코로나19\" + 0.007*\"소비\" + 0.006*\"음식\" + 0.006*\"트렌드\" + 0.005*\"건강\" + 0.004*\"증가\" + 0.004*\"변화\" + 0.004*\"사람\" + 0.004*\"가족\" + 0.004*\"식사\" + 0.004*\"요리\" + 0.003*\"공간\" + 0.003*\"제품\" + 0.003*\"생각\" + 0.003*\"생활\" + 0.003*\"조사\" + 0.003*\"사람들\" + 0.003*\"세대\" + 0.003*\"온라인\" + 0.003*\"시대\" + 0.003*\"확산\" + 0.003*\"문화\" + 0.003*\"사용\" + 0.002*\"사회\" + 0.002*\"이용\" + 0.002*\"결과\" + 0.002*\"전망\" + 0.002*\"정도\" + 0.002*\"밀키트\"')\n",
            "(8, '0.025*\"선물\" + 0.016*\"세트\" + 0.012*\"판매\" + 0.012*\"밀키트\" + 0.008*\"산천어\" + 0.008*\"명절\" + 0.007*\"추석\" + 0.007*\"KT\" + 0.006*\"진행\" + 0.005*\"광화문\" + 0.005*\"사회\" + 0.004*\"제공\" + 0.004*\"구매\" + 0.004*\"지역\" + 0.004*\"사랑\" + 0.004*\"전달\" + 0.004*\"코로나19\" + 0.004*\"선물세트\" + 0.004*\"지원\" + 0.004*\"서비스\" + 0.004*\"구성\" + 0.004*\"준비\" + 0.003*\"축제\" + 0.003*\"캠페인\" + 0.003*\"조리\" + 0.003*\"식당\" + 0.003*\"큐커\" + 0.003*\"보양식\" + 0.003*\"대상\" + 0.003*\"한우\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UOWFO2P0wJU"
      },
      "source": [
        "---\n",
        "# **불러와서 분석**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdK4rGo40wJU",
        "outputId": "ac3b305a-4983-4772-b531-e148847a7ae5"
      },
      "source": [
        "dictionary = gensim.corpora.Dictionary.load('dictionary_전처리.gensim')\n",
        "corpus = pickle.load(open('corpus_전처리.pkl', 'rb'))\n",
        "ldamodel = gensim.models.ldamodel.LdaModel.load('gensim_model_전처리.gensim')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/smart_open/smart_open_lib.py:494: DeprecationWarning: This function is deprecated.  See https://github.com/RaRe-Technologies/smart_open/blob/develop/MIGRATING_FROM_OLDER_VERSIONS.rst for more information\n",
            "  warnings.warn(message, category=DeprecationWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/smart_open/smart_open_lib.py:494: DeprecationWarning: This function is deprecated.  See https://github.com/RaRe-Technologies/smart_open/blob/develop/MIGRATING_FROM_OLDER_VERSIONS.rst for more information\n",
            "  warnings.warn(message, category=DeprecationWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/smart_open/smart_open_lib.py:494: DeprecationWarning: This function is deprecated.  See https://github.com/RaRe-Technologies/smart_open/blob/develop/MIGRATING_FROM_OLDER_VERSIONS.rst for more information\n",
            "  warnings.warn(message, category=DeprecationWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/smart_open/smart_open_lib.py:494: DeprecationWarning: This function is deprecated.  See https://github.com/RaRe-Technologies/smart_open/blob/develop/MIGRATING_FROM_OLDER_VERSIONS.rst for more information\n",
            "  warnings.warn(message, category=DeprecationWarning)\n"
          ]
        }
      ]
    }
  ]
}